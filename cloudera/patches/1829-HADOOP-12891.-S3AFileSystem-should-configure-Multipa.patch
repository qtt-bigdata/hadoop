From f9e401f0304e1b1ca16cb80604219b841e967cef Mon Sep 17 00:00:00 2001
From: Steve Loughran <stevel@apache.org>
Date: Fri, 22 Apr 2016 11:24:24 +0100
Subject: [PATCH 1829/2848] HADOOP-12891. S3AFileSystem should configure
 Multipart Copy threshold and chunk size. (Andrew
 Olson via stevel)

(cherry picked from commit 5df89f9a8a4adc16820f28289878b5f800878447)

Conflicts:
	hadoop-common-project/hadoop-common/src/main/resources/core-default.xml

Change-Id: I079c7a9d1aca61d1b45fbaf81d06b4e27b5689fe
---
 .../src/main/resources/core-default.xml            |    5 ++++-
 .../org/apache/hadoop/fs/s3a/S3AFileSystem.java    |    2 ++
 .../src/site/markdown/tools/hadoop-aws/index.md    |    4 +++-
 3 files changed, 9 insertions(+), 2 deletions(-)

diff --git a/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml b/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
index bec0288..d49ffcf 100644
--- a/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
+++ b/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
@@ -933,7 +933,10 @@ for ldap providers in the same way as above does.
 <property>
   <name>fs.s3a.multipart.threshold</name>
   <value>16777216</value>
-  <description>Threshold before uploads or copies use parallel multipart operations.</description>
+  <description>How big (in bytes) to split upload or copy operations up into.
+    This also controls the partition size in renamed files, as rename() involves
+    copying the source file(s)
+  </description>
 </property>
 
 <property>
diff --git a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java b/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java
index 941d07f..33247fd 100644
--- a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java
+++ b/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java
@@ -324,6 +324,8 @@ private void initTransferManager() {
     TransferManagerConfiguration transferConfiguration = new TransferManagerConfiguration();
     transferConfiguration.setMinimumUploadPartSize(partSize);
     transferConfiguration.setMultipartUploadThreshold(multiPartThreshold);
+    transferConfiguration.setMultipartCopyPartSize(partSize);
+    transferConfiguration.setMultipartCopyThreshold(multiPartThreshold);
 
     transfers = new TransferManager(s3, threadPoolExecutor);
     transfers.setConfiguration(transferConfiguration);
diff --git a/hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/index.md b/hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/index.md
index f6fc124..f0dcd71 100644
--- a/hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/index.md
+++ b/hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/index.md
@@ -390,7 +390,9 @@ this capability.
     <property>
       <name>fs.s3a.multipart.size</name>
       <value>104857600</value>
-      <description>How big (in bytes) to split upload or copy operations up into.</description>
+      <description>How big (in bytes) to split upload or copy operations up into.
+      This also controls the partition size in renamed files, as rename() involves
+      copying the source file(s)</description>
     </property>
 
     <property>
-- 
1.7.9.5

