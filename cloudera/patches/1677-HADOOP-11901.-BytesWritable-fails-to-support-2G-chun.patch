From a9c67d4a261d07ca4b0f2a9563eb21383f89ed66 Mon Sep 17 00:00:00 2001
From: Haohui Mai <wheat9@apache.org>
Date: Thu, 19 Nov 2015 12:54:08 -0800
Subject: [PATCH 1677/2848] HADOOP-11901. BytesWritable fails to support 2G
 chunks due to integer overflow. Contributed by
 Reynold Xin.

(cherry picked from commit 03c292efb7338599d1a1d9a8b5a5a1a3ff94eacd)

Change-Id: I437bc00f911013ab07f26f28588336d49849ffb9
(cherry picked from commit 63154f605bb40812f28fba4301e3a516699a5e9e)
---
 .../java/org/apache/hadoop/io/BytesWritable.java   |    4 +++-
 1 file changed, 3 insertions(+), 1 deletion(-)

diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/BytesWritable.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/BytesWritable.java
index 155df3a..7d7b75b 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/BytesWritable.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/BytesWritable.java
@@ -120,7 +120,9 @@ public int getSize() {
    */
   public void setSize(int size) {
     if (size > getCapacity()) {
-      setCapacity(size * 3 / 2);
+      // Avoid overflowing the int too early by casting to a long.
+      long newSize = Math.min(Integer.MAX_VALUE, (3L * size) / 2L);
+      setCapacity((int) newSize);
     }
     this.size = size;
   }
-- 
1.7.9.5

