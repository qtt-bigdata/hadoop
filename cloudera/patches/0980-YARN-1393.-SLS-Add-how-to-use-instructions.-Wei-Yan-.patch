From 2e690a66abef5c6d4e189ff2e5c34bd255f68c56 Mon Sep 17 00:00:00 2001
From: Karthik Kambatla <kasha@apache.org>
Date: Tue, 3 Feb 2015 13:20:41 -0800
Subject: [PATCH 0980/2848] YARN-1393. SLS: Add how-to-use instructions. (Wei
 Yan via kasha)

(cherry picked from commit c559df2219f4049f2412fba8ad031c434d9e82b6)
(cherry picked from commit c981b040ba22d0370f0aa1daeace332f7d9f7707)

Change-Id: I993ff329576bdb39452ed3d8c9e3cf4f6a07c4d9
---
 hadoop-tools/hadoop-sls/README                     |   24 ++++++++++++++++++--
 .../src/site/apt/SchedulerLoadSimulator.apt.vm     |    5 ++--
 2 files changed, 25 insertions(+), 4 deletions(-)

diff --git a/hadoop-tools/hadoop-sls/README b/hadoop-tools/hadoop-sls/README
index 86b554e..3d7912e 100644
--- a/hadoop-tools/hadoop-sls/README
+++ b/hadoop-tools/hadoop-sls/README
@@ -8,5 +8,25 @@ SLS runs a regular RM without RPC endpoints and uses a NodeManager and
 Application Manager simulators to send and receive events simulating cluster
 and application load behavior.
 
-The size of the cluster and the application load is scripted in a configuration
-file.
+==== Quick Start ====
+
+Let $HADOOP_ROOT represent the Hadoop install directory. If you build Hadoop
+yourself, $HADOOP_ROOT is hadoop-dist/target/hadoop-$VERSION. The simulator 
+is located at $HADOOP_ROOT/share/hadoop/tools/sls. The folder sls contains 
+four directories: bin (running scripts), html (web portal to view progress),
+sample-conf (some example configurations), and sample-data (an example rumen
+trace).
+
+STEP 1: Copy all configuration files (under sample-conf) to $HADOOP_ROOT/etc/hadoop.
+STEP 2: Go to the $HADOOP_ROOT/share/hadoop/tools/sls directory, and run the simulator 
+using the sample rumen trace (under sample-data).
+
+bin/slsrun.sh —-input-rumen=sample-data/2jobs2min-rumen-jh.json —-output-dir=sample-output
+
+The simulator will start to run, and you can track the running progress 
+using its web portal (http://$HOST:10001/simulate, where $HOST is the place 
+where you run the simulator.). All collected scheduler metrics are stored 
+under the output-dir during running. This trace takes about 3 mins to finish.
+
+For more detailed setup, you can check out the document 
+(http://issues.apache.org/jira/secure/attachment/12604817/YARN-1021.pdf) 
diff --git a/hadoop-tools/hadoop-sls/src/site/apt/SchedulerLoadSimulator.apt.vm b/hadoop-tools/hadoop-sls/src/site/apt/SchedulerLoadSimulator.apt.vm
index 399a1f5..a8b408c 100644
--- a/hadoop-tools/hadoop-sls/src/site/apt/SchedulerLoadSimulator.apt.vm
+++ b/hadoop-tools/hadoop-sls/src/site/apt/SchedulerLoadSimulator.apt.vm
@@ -225,7 +225,8 @@ Yarn Scheduler Load Simulator (SLS)
   input traces. The script to start the simulator is <<<slsrun.sh>>>.
 
 +----+
-$ $HADOOP_ROOT/share/hadoop/tools/sls/bin/slsrun.sh
+$ cd $HADOOP_ROOT/share/hadoop/tools/sls
+$ bin/slsrun.sh
     --input-rumen|--input-sls=<TRACE_FILE1,TRACE_FILE2,...>
     --output-dir=<SLS_SIMULATION_OUTPUT_DIRECTORY> [--nodes=<SLS_NODES_FILE>]
     [--track-jobs=<JOBID1,JOBID2,...>] [--print-simulation]
@@ -258,7 +259,7 @@ $ $HADOOP_ROOT/share/hadoop/tools/sls/bin/slsrun.sh
   convert rumen traces to sls traces.
 
 +----+
-$ $HADOOP_ROOT/share/hadoop/tools/sls/bin/rumen2sls.sh
+$ bin/rumen2sls.sh
     --rumen-file=<RUMEN_FILE>
     --output-dir=<SLS_OUTPUT_DIRECTORY>
     [--output-prefix=<SLS_FILE_PREFIX>]
-- 
1.7.9.5

