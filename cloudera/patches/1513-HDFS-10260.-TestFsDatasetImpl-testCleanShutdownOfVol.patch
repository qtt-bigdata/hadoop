From a456a7b3b6160cca4fbe75134cbf8e4986d1bbf0 Mon Sep 17 00:00:00 2001
From: Kihwal Lee <kihwal@apache.org>
Date: Fri, 29 Apr 2016 10:05:58 -0500
Subject: [PATCH 1513/2848] HDFS-10260.
 TestFsDatasetImpl#testCleanShutdownOfVolume often
 fails. Contributed by Rushabh Shah.

(cherry picked from commit af9b000535cc987f66327e2b2bfe08923ba24c13)
(cherry picked from commit a4db3729be30ea247a7b699ac76e1d195b1a8fdc)

Change-Id: I711fd17bd678ffa588cd7901dad5f9d7c55377a3
---
 .../datanode/fsdataset/impl/TestFsDatasetImpl.java |   15 +++++++++------
 1 file changed, 9 insertions(+), 6 deletions(-)

diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestFsDatasetImpl.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestFsDatasetImpl.java
index 69a6386..47faffb 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestFsDatasetImpl.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestFsDatasetImpl.java
@@ -17,6 +17,7 @@
  */
 package org.apache.hadoop.hdfs.server.datanode.fsdataset.impl;
 
+import com.google.common.base.Supplier;
 import com.google.common.collect.Lists;
 
 import org.apache.commons.io.FileUtils;
@@ -554,8 +555,8 @@ public void testCleanShutdownOfVolume() throws Exception {
       out.hflush();
 
       ExtendedBlock block = DFSTestUtil.getFirstBlock(fs, filePath);
-      FsVolumeImpl volume = (FsVolumeImpl) dataNode.getFSDataset().getVolume(
-          block);
+      final FsVolumeImpl volume = (FsVolumeImpl) dataNode.getFSDataset().
+          getVolume(block);
       File finalizedDir = volume.getFinalizedDir(cluster.getNamesystem()
           .getBlockPoolId());
 
@@ -570,9 +571,11 @@ public void testCleanShutdownOfVolume() throws Exception {
       // Invoke the synchronous checkDiskError method
       dataNode.getFSDataset().checkDataDir();
       // Sleep for 1 second so that datanode can interrupt and cluster clean up
-      Thread.sleep(1000);
-      assertEquals("There are active threads still referencing volume: "
-          + volume.getBasePath(), 0, volume.getReferenceCount());
+      GenericTestUtils.waitFor(new Supplier<Boolean>() {
+          @Override public Boolean get() {
+              return volume.getReferenceCount() == 0;
+            }
+          }, 100, 10);
       LocatedBlock lb = DFSTestUtil.getAllBlocks(fs, filePath).get(0);
       DatanodeInfo info = lb.getLocations()[0];
 
@@ -581,7 +584,7 @@ public void testCleanShutdownOfVolume() throws Exception {
         Assert.fail("This is not a valid code path. "
             + "out.close should have thrown an exception.");
       } catch (IOException ioe) {
-        Assert.assertTrue(ioe.getMessage().contains(info.toString()));
+        GenericTestUtils.assertExceptionContains(info.toString(), ioe);
       }
       finalizedDir.setWritable(true);
       finalizedDir.setExecutable(true);
-- 
1.7.9.5

