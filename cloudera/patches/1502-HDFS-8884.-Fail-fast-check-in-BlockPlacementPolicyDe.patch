From 3d93430f442653d19d888e3c7deb11c301037890 Mon Sep 17 00:00:00 2001
From: yliu <yliu@apache.org>
Date: Thu, 20 Aug 2015 20:08:20 +0800
Subject: [PATCH 1502/2848] HDFS-8884. Fail-fast check in
 BlockPlacementPolicyDefault#chooseTarget. (yliu)

(cherry picked from commit 63bdbb7793ea3ee70271984b2970ce4d28b6fd4b)

Conflicts:
	hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
	hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java
	hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDefaultBlockPlacementPolicy.java

Change-Id: I50f06f666b2b659a48c58ab91416d8d5a48d051d
---
 .../BlockPlacementPolicyDefault.java               |  176 ++++++++++++--------
 .../BlockPlacementPolicyWithNodeGroup.java         |   34 +---
 .../namenode/TestDefaultBlockPlacementPolicy.java  |   52 +++++-
 3 files changed, 158 insertions(+), 104 deletions(-)

diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
index 7697324..a0a84d2 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
@@ -436,17 +436,11 @@ protected Node chooseTargetInOrder(int numOfReplicas,
         maxNodesPerRack, results, avoidStaleNodes, storageTypes);
     return writer;
   }
-  
-  /**
-   * Choose <i>localMachine</i> as the target.
-   * if <i>localMachine</i> is not available, 
-   * choose a node on the same rack
-   * @return the chosen storage
-   */
+
   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,
       Set<Node> excludedNodes, long blocksize, int maxNodesPerRack,
       List<DatanodeStorageInfo> results, boolean avoidStaleNodes,
-      EnumMap<StorageType, Integer> storageTypes, boolean fallbackToLocalRack)
+      EnumMap<StorageType, Integer> storageTypes)
       throws NotEnoughReplicasException {
     // if no local machine, randomly choose one node
     if (localMachine == null) {
@@ -456,7 +450,9 @@ protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,
     if (preferLocalNode && localMachine instanceof DatanodeDescriptor) {
       DatanodeDescriptor localDatanode = (DatanodeDescriptor) localMachine;
       // otherwise try local machine first
-      if (excludedNodes.add(localMachine)) { // was not in the excluded list
+      if (excludedNodes.add(localMachine) // was not in the excluded list
+          && isGoodDatanode(localDatanode, maxNodesPerRack, false,
+              results, avoidStaleNodes)) {
         for (Iterator<Map.Entry<StorageType, Integer>> iter = storageTypes
             .entrySet().iterator(); iter.hasNext(); ) {
           Map.Entry<StorageType, Integer> entry = iter.next();
@@ -464,7 +460,7 @@ protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,
               localDatanode.getStorageInfos())) {
             StorageType type = entry.getKey();
             if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,
-                maxNodesPerRack, false, results, avoidStaleNodes, type) >= 0) {
+                results, type) >= 0) {
               int num = entry.getValue();
               if (num == 1) {
                 iter.remove();
@@ -477,6 +473,26 @@ protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,
         }
       } 
     }
+    return null;
+  }
+
+  /**
+   * Choose <i>localMachine</i> as the target.
+   * if <i>localMachine</i> is not available,
+   * choose a node on the same rack
+   * @return the chosen storage
+   */
+  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,
+      Set<Node> excludedNodes, long blocksize, int maxNodesPerRack,
+      List<DatanodeStorageInfo> results, boolean avoidStaleNodes,
+      EnumMap<StorageType, Integer> storageTypes, boolean fallbackToLocalRack)
+      throws NotEnoughReplicasException {
+    DatanodeStorageInfo localStorage = chooseLocalStorage(localMachine,
+        excludedNodes, blocksize, maxNodesPerRack, results,
+        avoidStaleNodes, storageTypes);
+    if (localStorage != null) {
+      return localStorage;
+    }
 
     if (!fallbackToLocalRack) {
       return null;
@@ -652,6 +668,14 @@ protected DatanodeStorageInfo chooseRandom(int numOfReplicas,
           builder.append("\nNode ").append(NodeBase.getPath(chosenNode)).append(" [");
         }
         numOfAvailableNodes--;
+        if (!isGoodDatanode(chosenNode, maxNodesPerRack, considerLoad,
+            results, avoidStaleNodes)) {
+          if (LOG.isDebugEnabled()) {
+            builder.append("\n]");
+          }
+          badTarget = true;
+          continue;
+        }
 
         final DatanodeStorageInfo[] storages = DFSUtil.shuffle(
             chosenNode.getStorageInfos());
@@ -663,8 +687,7 @@ protected DatanodeStorageInfo chooseRandom(int numOfReplicas,
           for (i = 0; i < storages.length; i++) {
             StorageType type = entry.getKey();
             final int newExcludedNodes = addIfIsGoodTarget(storages[i],
-                excludedNodes, blocksize, maxNodesPerRack, considerLoad, results,
-                avoidStaleNodes, type);
+                excludedNodes, blocksize, results, type);
             if (newExcludedNodes >= 0) {
               numOfReplicas--;
               if (firstChosen == null) {
@@ -732,13 +755,9 @@ protected DatanodeDescriptor chooseDataNode(final String scope) {
   int addIfIsGoodTarget(DatanodeStorageInfo storage,
       Set<Node> excludedNodes,
       long blockSize,
-      int maxNodesPerRack,
-      boolean considerLoad,
-      List<DatanodeStorageInfo> results,                           
-      boolean avoidStaleNodes,
+      List<DatanodeStorageInfo> results,
       StorageType storageType) {
-    if (isGoodTarget(storage, blockSize, maxNodesPerRack, considerLoad,
-        results, avoidStaleNodes, storageType)) {
+    if (isGoodTarget(storage, blockSize, results, storageType)) {
       results.add(storage);
       // add node and related nodes to excludedNode
       return addToExcludedNodes(storage.getDatanodeDescriptor(), excludedNodes);
@@ -756,27 +775,86 @@ private static void logNodeIsNotChosen(DatanodeStorageInfo storage, String reaso
     }
   }
 
+  private static void logNodeIsNotChosen(DatanodeDescriptor node,
+      String reason) {
+    if (LOG.isDebugEnabled()) {
+      // build the error message for later use.
+      debugLoggingBuilder.get()
+          .append("\n  Datanode ").append(node)
+          .append(" is not chosen since ").append(reason).append(".");
+    }
+  }
+
   /**
-   * Determine if a storage is a good target. 
-   * 
-   * @param storage The target storage
-   * @param blockSize Size of block
-   * @param maxTargetPerRack Maximum number of targets per rack. The value of 
-   *                       this parameter depends on the number of racks in 
+   * Determine if a datanode is good for placing block.
+   *
+   * @param node The target datanode
+   * @param maxTargetPerRack Maximum number of targets per rack. The value of
+   *                       this parameter depends on the number of racks in
    *                       the cluster and total number of replicas for a block
    * @param considerLoad whether or not to consider load of the target node
-   * @param results A list containing currently chosen nodes. Used to check if 
+   * @param results A list containing currently chosen nodes. Used to check if
    *                too many nodes has been chosen in the target rack.
    * @param avoidStaleNodes Whether or not to avoid choosing stale nodes
-   * @return Return true if <i>node</i> has enough space, 
-   *         does not have too much load, 
-   *         and the rack does not have too many nodes.
+   * @return Reture true if the datanode is good candidate, otherwise false
+   */
+  boolean isGoodDatanode(DatanodeDescriptor node,
+                         int maxTargetPerRack, boolean considerLoad,
+                         List<DatanodeStorageInfo> results,
+                         boolean avoidStaleNodes) {
+    // check if the node is (being) decommissioned
+    if (node.isDecommissionInProgress() || node.isDecommissioned()) {
+      logNodeIsNotChosen(node, "the node is (being) decommissioned ");
+      return false;
+    }
+
+    if (avoidStaleNodes) {
+      if (node.isStale(this.staleInterval)) {
+        logNodeIsNotChosen(node, "the node is stale ");
+        return false;
+      }
+    }
+
+    // check the communication traffic of the target machine
+    if (considerLoad) {
+      final double maxLoad = 2.0 * stats.getInServiceXceiverAverage();
+      final int nodeLoad = node.getXceiverCount();
+      if (nodeLoad > maxLoad) {
+        logNodeIsNotChosen(node, "the node is too busy (load: " + nodeLoad
+            + " > " + maxLoad + ") ");
+        return false;
+      }
+    }
+
+    // check if the target rack has chosen too many nodes
+    String rackname = node.getNetworkLocation();
+    int counter=1;
+    for(DatanodeStorageInfo resultStorage : results) {
+      if (rackname.equals(
+          resultStorage.getDatanodeDescriptor().getNetworkLocation())) {
+        counter++;
+      }
+    }
+    if (counter > maxTargetPerRack) {
+      logNodeIsNotChosen(node, "the rack has too many chosen nodes ");
+      return false;
+    }
+
+    return true;
+  }
+
+  /**
+   * Determine if a storage is a good target.
+   *
+   * @param storage The target storage
+   * @param blockSize Size of block
+   * @param results A list containing currently chosen nodes. Used to check if
+   *                too many nodes has been chosen in the target rack.
+   * @return Return true if <i>node</i> has enough space.
    */
   private boolean isGoodTarget(DatanodeStorageInfo storage,
-                               long blockSize, int maxTargetPerRack,
-                               boolean considerLoad,
+                               long blockSize,
                                List<DatanodeStorageInfo> results,
-                               boolean avoidStaleNodes,
                                StorageType requiredStorageType) {
     if (storage.getStorageType() != requiredStorageType) {
       logNodeIsNotChosen(storage, "storage types do not match,"
@@ -794,19 +872,7 @@ private boolean isGoodTarget(DatanodeStorageInfo storage,
     }
 
     DatanodeDescriptor node = storage.getDatanodeDescriptor();
-    // check if the node is (being) decommissioned
-    if (node.isDecommissionInProgress() || node.isDecommissioned()) {
-      logNodeIsNotChosen(storage, "the node is (being) decommissioned ");
-      return false;
-    }
 
-    if (avoidStaleNodes) {
-      if (node.isStale(this.staleInterval)) {
-        logNodeIsNotChosen(storage, "the node is stale ");
-        return false;
-      }
-    }
-    
     final long requiredSize = blockSize * HdfsConstants.MIN_BLOCKS_FOR_WRITE;
     final long scheduledSize = blockSize * node.getBlocksScheduled(storage.getStorageType());
     final long remaining =
@@ -820,30 +886,6 @@ private boolean isGoodTarget(DatanodeStorageInfo storage,
       return false;
     }
 
-    // check the communication traffic of the target machine
-    if (considerLoad) {
-      final double maxLoad = 2.0 * stats.getInServiceXceiverAverage();
-      final int nodeLoad = node.getXceiverCount();
-      if (nodeLoad > maxLoad) {
-        logNodeIsNotChosen(storage, "the node is too busy (load: " + nodeLoad
-            + " > " + maxLoad + ") ");
-        return false;
-      }
-    }
-      
-    // check if the target rack has chosen too many nodes
-    String rackname = node.getNetworkLocation();
-    int counter=1;
-    for(DatanodeStorageInfo resultStorage : results) {
-      if (rackname.equals(
-          resultStorage.getDatanodeDescriptor().getNetworkLocation())) {
-        counter++;
-      }
-    }
-    if (counter>maxTargetPerRack) {
-      logNodeIsNotChosen(storage, "the rack has too many chosen nodes ");
-      return false;
-    }
     return true;
   }
 
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java
index c3150f5..63e7f7d 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java
@@ -20,7 +20,6 @@
 import java.util.*;
 
 import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.hdfs.DFSUtil;
 import org.apache.hadoop.hdfs.StorageType;
 import org.apache.hadoop.hdfs.protocol.DatanodeInfo;
 import org.apache.hadoop.hdfs.server.namenode.FSClusterStats;
@@ -66,34 +65,11 @@ protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,
       List<DatanodeStorageInfo> results, boolean avoidStaleNodes,
       EnumMap<StorageType, Integer> storageTypes, boolean fallbackToLocalRack)
       throws NotEnoughReplicasException {
-    // if no local machine, randomly choose one node
-    if (localMachine == null)
-      return chooseRandom(NodeBase.ROOT, excludedNodes, 
-          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);
-
-    // otherwise try local machine first
-    if (localMachine instanceof DatanodeDescriptor) {
-      DatanodeDescriptor localDataNode = (DatanodeDescriptor)localMachine;
-      if (excludedNodes.add(localMachine)) { // was not in the excluded list
-        for (Iterator<Map.Entry<StorageType, Integer>> iter = storageTypes
-            .entrySet().iterator(); iter.hasNext(); ) {
-          Map.Entry<StorageType, Integer> entry = iter.next();
-          for (DatanodeStorageInfo localStorage : DFSUtil.shuffle(
-              localDataNode.getStorageInfos())) {
-            StorageType type = entry.getKey();
-            if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,
-                maxNodesPerRack, false, results, avoidStaleNodes, type) >= 0) {
-              int num = entry.getValue();
-              if (num == 1) {
-                iter.remove();
-              } else {
-                entry.setValue(num - 1);
-              }
-              return localStorage;
-            }
-          }
-        }
-      }
+    DatanodeStorageInfo localStorage = chooseLocalStorage(localMachine,
+        excludedNodes, blocksize, maxNodesPerRack, results,
+        avoidStaleNodes, storageTypes);
+    if (localStorage != null) {
+      return localStorage;
     }
 
     // try a node on local node group
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDefaultBlockPlacementPolicy.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDefaultBlockPlacementPolicy.java
index 867c389..659beeb 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDefaultBlockPlacementPolicy.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDefaultBlockPlacementPolicy.java
@@ -33,8 +33,11 @@
 import org.apache.hadoop.hdfs.DFSConfigKeys;
 import org.apache.hadoop.hdfs.HdfsConfiguration;
 import org.apache.hadoop.hdfs.MiniDFSCluster;
+import org.apache.hadoop.hdfs.protocol.DatanodeInfo;
 import org.apache.hadoop.hdfs.protocol.HdfsFileStatus;
 import org.apache.hadoop.hdfs.protocol.LocatedBlock;
+import org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor;
+import org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager;
 import org.apache.hadoop.hdfs.server.protocol.NamenodeProtocols;
 import org.apache.hadoop.net.StaticMapping;
 import org.apache.hadoop.security.AccessControlException;
@@ -88,7 +91,37 @@ public void testLocalRackPlacement() throws Exception {
     // Map client to RACK2
     String clientRack = "/RACK2";
     StaticMapping.addNodeToRack(clientMachine, clientRack);
-    testPlacement(clientMachine, clientRack);
+    testPlacement(clientMachine, clientRack, true);
+  }
+
+  /**
+   * Verify local node selection
+   */
+  @Test
+  public void testLocalStoragePlacement() throws Exception {
+    String clientMachine = "/host3";
+    testPlacement(clientMachine, "/RACK3", true);
+  }
+
+  /**
+   * Verify decommissioned nodes should not be selected.
+   */
+  @Test
+  public void testPlacementWithLocalRackNodesDecommissioned() throws Exception {
+    String clientMachine = "client.foo.com";
+    // Map client to RACK3
+    String clientRack = "/RACK3";
+    StaticMapping.addNodeToRack(clientMachine, clientRack);
+    final DatanodeManager dnm = namesystem.getBlockManager().getDatanodeManager();
+    DatanodeDescriptor dnd3 = dnm.getDatanode(
+        cluster.getDataNodes().get(3).getDatanodeId());
+    assertEquals(dnd3.getNetworkLocation(), clientRack);
+    dnm.startDecommission(dnd3);
+    try {
+      testPlacement(clientMachine, clientRack, false);
+    } finally {
+      dnm.stopDecommission(dnd3);
+    }
   }
 
   /**
@@ -100,14 +133,11 @@ public void testRandomRackSelectionForRemoteClient() throws Exception {
     // Don't map client machine to any rack,
     // so by default it will be treated as /default-rack
     // in that case a random node should be selected as first node.
-    testPlacement(clientMachine, null);
+    testPlacement(clientMachine, null, true);
   }
 
   private void testPlacement(String clientMachine,
-      String clientRack) throws AccessControlException,
-      SafeModeException, FileAlreadyExistsException, UnresolvedLinkException,
-      FileNotFoundException, ParentNotDirectoryException, IOException,
-      NotReplicatedYetException {
+      String clientRack, boolean hasBlockReplicaOnRack) throws IOException {
     // write 5 files and check whether all times block placed
     for (int i = 0; i < 5; i++) {
       String src = "/test-" + i;
@@ -121,8 +151,14 @@ private void testPlacement(String clientMachine,
       assertEquals("Block should be allocated sufficient locations",
           REPLICATION_FACTOR, locatedBlock.getLocations().length);
       if (clientRack != null) {
-        assertEquals("First datanode should be rack local", clientRack,
-            locatedBlock.getLocations()[0].getNetworkLocation());
+        if (hasBlockReplicaOnRack) {
+          assertEquals("First datanode should be rack local", clientRack,
+              locatedBlock.getLocations()[0].getNetworkLocation());
+        } else {
+          for (DatanodeInfo dni : locatedBlock.getLocations()) {
+            assertNotEquals(clientRack, dni.getNetworkLocation());
+          }
+        }
       }
       nameNodeRpc.abandonBlock(locatedBlock.getBlock(), fileStatus.getFileId(),
           src, clientMachine);
-- 
1.7.9.5

