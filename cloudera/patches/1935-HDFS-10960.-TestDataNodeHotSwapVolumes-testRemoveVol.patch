From 919a4e795a55497e9606e88bcfe76f50b6fe2cde Mon Sep 17 00:00:00 2001
From: Lei Xu <lei@apache.org>
Date: Fri, 14 Oct 2016 15:00:27 -0700
Subject: [PATCH 1935/2848] HDFS-10960.
 TestDataNodeHotSwapVolumes#testRemoveVolumeBeingWritten
 fails at disk error verification after volume
 remove. (Manoj Govindassamy via lei)

(cherry picked from commit 78cb79fa915ad0ca26d649ad88fdb44b310a99d8)

Change-Id: Ia41eecc46ec5c4b06b58bde4c6bc109ed15767e2
---
 .../datanode/TestDataNodeHotSwapVolumes.java       |   18 +++++++++++-------
 1 file changed, 11 insertions(+), 7 deletions(-)

diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java
index f56fcba..41b5d69 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java
@@ -636,8 +636,6 @@ private void testRemoveVolumeBeingWrittenForDatanode(int dataNodeIdx)
     final DataNode dn = cluster.getDataNodes().get(dataNodeIdx);
     final FileSystem fs = cluster.getFileSystem();
     final Path testFile = new Path("/test");
-    final long lastTimeDiskErrorCheck = dn.getLastDiskErrorCheck();
-
     FSDataOutputStream out = fs.create(testFile, REPLICATION);
 
     Random rb = new Random(0);
@@ -691,17 +689,23 @@ public void run() {
 
     reconfigThread.join();
 
+    // Verify if the data directory reconfigure was successful
+    FsDatasetSpi<? extends FsVolumeSpi> fsDatasetSpi = dn.getFSDataset();
+    try (FsDatasetSpi.FsVolumeReferences fsVolumeReferences = fsDatasetSpi
+        .getFsVolumeReferences()) {
+      for (int i =0; i < fsVolumeReferences.size(); i++) {
+        System.out.println("Vol: " + fsVolumeReferences.get(i).getBasePath());
+      }
+      assertEquals("Volume remove wasn't successful.",
+          1, fsVolumeReferences.size());
+    }
+
     // Verify the file has sufficient replications.
     DFSTestUtil.waitReplication(fs, testFile, REPLICATION);
     // Read the content back
     byte[] content = DFSTestUtil.readFileBuffer(fs, testFile);
     assertEquals(BLOCK_SIZE, content.length);
 
-    // If an IOException thrown from BlockReceiver#run, it triggers
-    // DataNode#checkDiskError(). So we can test whether checkDiskError() is called,
-    // to see whether there is IOException in BlockReceiver#run().
-    assertEquals(lastTimeDiskErrorCheck, dn.getLastDiskErrorCheck());
-
     if (!exceptions.isEmpty()) {
       throw new IOException(exceptions.get(0).getCause());
     }
-- 
1.7.9.5

