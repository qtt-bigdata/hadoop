From b5961835b3bddc0a8e890b8d76bc576329607038 Mon Sep 17 00:00:00 2001
From: John Zhuge <jzhuge@cloudera.com>
Date: Sun, 14 Aug 2016 15:35:21 -0700
Subject: [PATCH 1744/2848] HDFS-10693. metaSave should print blocks, not
 LightWeightHashSet. Contributed by Yuanbo Liu.

(cherry picked from commit 4d3af47f2765f6f57936d316ef2a4150b787cc97)
(cherry picked from commit bfc261f2a093fb2870e4ec758c2cc7c82d8ec347)

Change-Id: I678bade593d4fea897590d5b19d7c1ea7eef37cc
---
 .../server/blockmanagement/InvalidateBlocks.java   |    7 ++++---
 .../hadoop/hdfs/server/namenode/TestMetaSave.java  |    4 +++-
 2 files changed, 7 insertions(+), 4 deletions(-)

diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/InvalidateBlocks.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/InvalidateBlocks.java
index e357528..0cc4454 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/InvalidateBlocks.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/InvalidateBlocks.java
@@ -32,6 +32,7 @@
 import org.apache.hadoop.hdfs.protocol.DatanodeInfo;
 import org.apache.hadoop.hdfs.server.namenode.NameNode;
 import org.apache.hadoop.hdfs.util.LightWeightHashSet;
+import org.apache.hadoop.util.StringUtils;
 import org.apache.hadoop.util.Time;
 import org.apache.hadoop.hdfs.DFSUtil;
 
@@ -140,7 +141,7 @@ synchronized void remove(final DatanodeInfo dn, final Block block) {
   /** Print the contents to out. */
   synchronized void dump(final PrintWriter out) {
     final int size = node2blocks.values().size();
-    out.println("Metasave: Blocks " + numBlocks 
+    out.println("Metasave: Blocks " + numBlocks
         + " waiting deletion from " + size + " datanodes.");
     if (size == 0) {
       return;
@@ -150,7 +151,7 @@ synchronized void dump(final PrintWriter out) {
       final LightWeightHashSet<Block> blocks = entry.getValue();
       if (blocks.size() > 0) {
         out.println(entry.getKey());
-        out.println(blocks);
+        out.println(StringUtils.join(",", blocks));
       }
     }
   }
@@ -196,7 +197,7 @@ long getInvalidationDelay() {
     numBlocks -= toInvalidate.size();
     return toInvalidate;
   }
-  
+
   synchronized void clear() {
     node2blocks.clear();
     numBlocks = 0;
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestMetaSave.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestMetaSave.java
index 8065b20..b801dfb 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestMetaSave.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestMetaSave.java
@@ -162,7 +162,9 @@ public void testMetasaveAfterDelete()
       assertTrue(line.equals("Metasave: Blocks 2 waiting deletion from 1 datanodes."));
      //skip 2 lines to reach HDFS-9033 scenario.
       line = reader.readLine();
+      // skip 1 line for Corrupt Blocks section.
       line = reader.readLine();
+      assertTrue(line.contains("blk"));
       line = reader.readLine();
       assertTrue(line.equals("Metasave: Number of datanodes: 2"));
       line = reader.readLine();
@@ -220,7 +222,7 @@ public static void tearDown() throws IOException {
 
   /**
    * Returns a File for the given name inside the log directory.
-   * 
+   *
    * @param name String file name
    * @return File for given name inside log directory
    */
-- 
1.7.9.5

