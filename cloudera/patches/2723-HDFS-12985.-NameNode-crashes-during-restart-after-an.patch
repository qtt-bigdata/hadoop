From bb61b3f81a24dbfe4f9b0600b200adf61e1c6cea Mon Sep 17 00:00:00 2001
From: Manoj Govindassamy <manojpec@apache.org>
Date: Mon, 8 Jan 2018 16:21:21 -0800
Subject: [PATCH 2723/2848] HDFS-12985. NameNode crashes during restart after
 an OpenForWrite file present in the Snapshot got
 deleted.

(cherry picked from commit eadd3cecf9421e4839f3965c6c19ea618c54250f)

Conflicts:
	hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java

Change-Id: Icaf96de54b8fbd9d4806133783a0ca9f4d9c7af6
---
 .../hadoop/hdfs/server/namenode/INodeFile.java     |   20 +++++----
 .../snapshot/TestOpenFilesWithSnapshot.java        |   45 ++++++++++++++++++++
 2 files changed, 57 insertions(+), 8 deletions(-)

diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java
index a278a87..9a6ecf8 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java
@@ -482,14 +482,22 @@ public void setBlocks(BlockInfo[] blocks) {
     this.blocks = blocks;
   }
 
+  private void updateRemovedUnderConstructionFiles( List<Long> removedUCFiles) {
+    if (isUnderConstruction() && removedUCFiles != null) {
+      removedUCFiles.add(getId());
+    }
+  }
+
   @Override
   public Quota.Counts cleanSubtree(final int snapshot, int priorSnapshotId,
       final BlocksMapUpdateInfo collectedBlocks,
       final List<INode> removedINodes, List<Long> removedUCFiles) {
     FileWithSnapshotFeature sf = getFileWithSnapshotFeature();
     if (sf != null) {
-      return sf.cleanFile(this, snapshot, priorSnapshotId, collectedBlocks,
-          removedINodes, removedUCFiles);
+      Quota.Counts counts = sf.cleanFile(this, snapshot, priorSnapshotId,
+          collectedBlocks, removedINodes, removedUCFiles);
+      updateRemovedUnderConstructionFiles(removedUCFiles);
+      return counts;
     }
     Quota.Counts counts = Quota.Counts.newInstance();
     if (snapshot == CURRENT_STATE_ID) {
@@ -504,9 +512,7 @@ public void setBlocks(BlockInfo[] blocks) {
         // clean the 0-sized block if the file is UC
         if (uc != null) {
           uc.cleanZeroSizeBlock(this, collectedBlocks);
-          if (removedUCFiles != null) {
-            removedUCFiles.add(getId());
-          }
+          updateRemovedUnderConstructionFiles(removedUCFiles);
         }
       }
     }
@@ -530,9 +536,7 @@ public void destroyAndCollectBlocks(BlocksMapUpdateInfo collectedBlocks,
     if (sf != null) {
       sf.clearDiffs();
     }
-    if (isUnderConstruction() && removedUCFiles != null) {
-      removedUCFiles.add(getId());
-    }
+    updateRemovedUnderConstructionFiles(removedUCFiles);
   }
 
   @Override
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestOpenFilesWithSnapshot.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestOpenFilesWithSnapshot.java
index 8efcde2..d49f1c2 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestOpenFilesWithSnapshot.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestOpenFilesWithSnapshot.java
@@ -637,6 +637,51 @@ public void testSnapshotsForOpenFilesAndDeletion() throws Exception {
   }
 
   /**
+   * Verify if the NameNode can restart properly after an OpenForWrite
+   * file and the only snapshot it was present in were deleted.
+   *
+   * @throws Exception
+   */
+  @Test (timeout = 600000)
+  public void testOpenFileDeletionAndNNRestart() throws Exception {
+    // Construct the directory tree
+    final Path snapRootDir = new Path("/level_0_A/test");
+    final String hbaseFileName = "hbase.log";
+    final String snap1Name = "snap_1";
+
+    // Create a file with few blocks. Get its output stream
+    // for append.
+    final Path hbaseFile = new Path(snapRootDir, hbaseFileName);
+    createFile(hbaseFile);
+    FSDataOutputStream hbaseOutputStream = fs.append(hbaseFile);
+
+    int newWriteLength = (int) (BLOCKSIZE * 1.5);
+    byte[] buf = new byte[newWriteLength];
+    Random random = new Random();
+    random.nextBytes(buf);
+
+    // Write more data to the file
+    writeToStream(hbaseOutputStream, buf);
+
+    // Take a snapshot while the file is open for write
+    final Path snap1Dir = SnapshotTestHelper.createSnapshot(
+        fs, snapRootDir, snap1Name);
+    LOG.info("Open file status in snap: " +
+        fs.getFileStatus(new Path(snap1Dir, hbaseFileName)));
+
+    // Delete the open file and the snapshot while
+    // its output stream is still open.
+    fs.delete(hbaseFile, true);
+    fs.deleteSnapshot(snapRootDir, snap1Name);
+    Assert.assertFalse(fs.exists(hbaseFile));
+
+    // Verify file existence after the NameNode restart
+    cluster.restartNameNode();
+    cluster.waitActive();
+    Assert.assertFalse(fs.exists(hbaseFile));
+  }
+
+  /**
    * Test client writing to open files are not interrupted when snapshots
    * that captured open files get deleted.
    */
-- 
1.7.9.5

