From fdeccdf8f2fa9f392acc9aeb16ab246e2150ffa2 Mon Sep 17 00:00:00 2001
From: Anu Engineer <aengineer@apache.org>
Date: Wed, 22 Jun 2016 17:35:55 -0700
Subject: [PATCH 1628/2848] HDFS-10552. DiskBalancer "-query" results in NPE
 if no plan for the node. Contributed by Anu
 Engineer.

(cherry picked from commit 8a6e3541226fb1b6798cedecc56f1f160012becf)

Change-Id: Icbc005847ab5afdb7a1a60f44c76e798822461f3
---
 .../hadoop/hdfs/server/datanode/DiskBalancer.java  |    5 +++-
 .../server/diskbalancer/command/QueryCommand.java  |    2 +-
 .../command/TestDiskBalancerCommand.java           |   25 ++++++++++++++++++++
 3 files changed, 30 insertions(+), 2 deletions(-)

diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java
index ea09054..9995efc 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java
@@ -104,6 +104,7 @@ public DiskBalancer(String dataNodeUUID,
     scheduler = Executors.newSingleThreadExecutor();
     lock = new ReentrantLock();
     workMap = new ConcurrentHashMap<>();
+    this.planID = "";  // to keep protobuf happy.
     this.isDiskBalancerEnabled = conf.getBoolean(
         DFSConfigKeys.DFS_DISK_BALANCER_ENABLED,
         DFSConfigKeys.DFS_DISK_BALANCER_ENABLED_DEFAULT);
@@ -223,7 +224,9 @@ public void cancelPlan(String planID) throws DiskBalancerException {
     lock.lock();
     try {
       checkDiskBalancerEnabled();
-      if ((this.planID == null) || (!this.planID.equals(planID))) {
+      if (this.planID == null ||
+          !this.planID.equals(planID) ||
+          this.planID.isEmpty()) {
         LOG.error("Disk Balancer - No such plan. Cancel plan failed. PlanID: " +
             planID);
         throw new DiskBalancerException("No such plan.",
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/QueryCommand.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/QueryCommand.java
index 3a3b97f..22ee42a 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/QueryCommand.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/QueryCommand.java
@@ -62,7 +62,7 @@ public void execute(CommandLine cmd) throws Exception {
     String nodeAddress = nodeName;
 
     // if the string is not name:port format use the default port.
-    if(!nodeName.matches("^.*:\\d$")) {
+    if (!nodeName.matches("[^\\:]+:[0-9]{2,5}")) {
       int defaultIPC = NetUtils.createSocketAddr(
           getConf().getTrimmed(DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_KEY,
               DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_DEFAULT)).getPort();
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java
index c1c137d..26f23d0 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java
@@ -35,6 +35,7 @@
 import org.apache.hadoop.hdfs.DFSConfigKeys;
 import org.apache.hadoop.hdfs.HdfsConfiguration;
 import org.apache.hadoop.hdfs.MiniDFSCluster;
+import org.apache.hadoop.hdfs.server.datanode.DataNode;
 import org.apache.hadoop.hdfs.server.diskbalancer.connectors.ClusterConnector;
 import org.apache.hadoop.hdfs.server.diskbalancer.connectors.ConnectorFactory;
 import org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster;
@@ -281,4 +282,28 @@ public void testReadClusterFromJson() throws Exception {
     }
     return outputs;
   }
+
+  /**
+   * Making sure that we can query the node without having done a submit.
+   * @throws Exception
+   */
+  @Test
+  public void testDiskBalancerQueryWithoutSubmit() throws Exception {
+    Configuration conf = new HdfsConfiguration();
+    conf.setBoolean(DFSConfigKeys.DFS_DISK_BALANCER_ENABLED, true);
+    final int numDatanodes = 2;
+    MiniDFSCluster miniDFSCluster = new MiniDFSCluster.Builder(conf)
+        .numDataNodes(numDatanodes).build();
+    try {
+      miniDFSCluster.waitActive();
+      DataNode dataNode = miniDFSCluster.getDataNodes().get(0);
+      final String queryArg = String.format("-query localhost:%d", dataNode
+          .getIpcPort());
+      final String cmdLine = String.format("hdfs diskbalancer %s",
+          queryArg);
+      runCommand(cmdLine);
+    } finally {
+      miniDFSCluster.shutdown();
+    }
+  }
 }
-- 
1.7.9.5

