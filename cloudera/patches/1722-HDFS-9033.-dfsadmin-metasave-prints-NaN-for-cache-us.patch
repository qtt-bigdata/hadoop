From 0ba3e2c85f767a38cca38d101fe45275ddf80691 Mon Sep 17 00:00:00 2001
From: John Zhuge <jzhuge@cloudera.com>
Date: Thu, 11 Aug 2016 13:36:12 -0700
Subject: [PATCH 1722/2848] HDFS-9033. dfsadmin -metasave prints "NaN" for
 cache used%. Contributed by Brahma Reddy Battula.

(cherry picked from commit 0113e4528deda7563b62a29745fbf209ab31b81a)
(cherry picked from commit eb9e06f8e30a6f930db478683739230f8f5ada5d)
(cherry picked from commit c5a74c5c37a1208b6b0077c723efc8f4c896711a)

Change-Id: Ifadadca034e2cfaf6c4646dee4cd80ffa124ac32
---
 .../apache/hadoop/hdfs/protocol/DatanodeInfo.java  |    6 ++++--
 .../hadoop/hdfs/server/namenode/TestMetaSave.java  |   11 +++++++++++
 2 files changed, 15 insertions(+), 2 deletions(-)

diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/DatanodeInfo.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/DatanodeInfo.java
index c3f51e8..30b8da7 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/DatanodeInfo.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/DatanodeInfo.java
@@ -347,9 +347,11 @@ public String dumpDatanode() {
     long c = getCapacity();
     long r = getRemaining();
     long u = getDfsUsed();
+    float usedPercent = getDfsUsedPercent();
     long cc = getCacheCapacity();
     long cr = getCacheRemaining();
     long cu = getCacheUsed();
+    float cacheUsedPercent = getCacheUsedPercent();
     buffer.append(getName());
     if (!NetworkTopology.DEFAULT_RACK.equals(location)) {
       buffer.append(" "+location);
@@ -363,11 +365,11 @@ public String dumpDatanode() {
     }
     buffer.append(" " + c + "(" + StringUtils.byteDesc(c)+")");
     buffer.append(" " + u + "(" + StringUtils.byteDesc(u)+")");
-    buffer.append(" " + percent2String(u/(double)c));
+    buffer.append(" " + percent2String(usedPercent));
     buffer.append(" " + r + "(" + StringUtils.byteDesc(r)+")");
     buffer.append(" " + cc + "(" + StringUtils.byteDesc(cc)+")");
     buffer.append(" " + cu + "(" + StringUtils.byteDesc(cu)+")");
-    buffer.append(" " + percent2String(cu/(double)cc));
+    buffer.append(" " + percent2String(cacheUsedPercent));
     buffer.append(" " + cr + "(" + StringUtils.byteDesc(cr)+")");
     buffer.append(" " + new Date(lastUpdate));
     return buffer.toString();
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestMetaSave.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestMetaSave.java
index 080dcee..8065b20 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestMetaSave.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestMetaSave.java
@@ -17,6 +17,7 @@
  */
 package org.apache.hadoop.hdfs.server.namenode;
 
+import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
@@ -157,6 +158,16 @@ public void testMetasaveAfterDelete()
       assertTrue(line.equals("Mis-replicated blocks that have been postponed:"));
       line = reader.readLine();
       assertTrue(line.equals("Metasave: Blocks being replicated: 0"));
+      line = reader.readLine();
+      assertTrue(line.equals("Metasave: Blocks 2 waiting deletion from 1 datanodes."));
+     //skip 2 lines to reach HDFS-9033 scenario.
+      line = reader.readLine();
+      line = reader.readLine();
+      line = reader.readLine();
+      assertTrue(line.equals("Metasave: Number of datanodes: 2"));
+      line = reader.readLine();
+      assertFalse(line.contains("NaN"));
+
     } finally {
       if (reader != null)
         reader.close();
-- 
1.7.9.5

